{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from os import system\n",
    "system(\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/vidalyago_94/buckets/b1/' )\n",
    "\n",
    "experimento='FE9252'\n",
    "\n",
    "dataset = pd.read_csv(\"./exp/FE9251/dataset.csv.gz\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vyago\\AppData\\Local\\Temp\\ipykernel_13796\\4139612435.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train=train.fillna(train.mean()) # RELLENO CON LA MEDIA DE CADA COLUMNA LOS VALORES NULOS, LO NECESITA LA RED\n",
      "C:\\Users\\vyago\\AppData\\Local\\Temp\\ipykernel_13796\\4139612435.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test = test.fillna(test.mean())\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------\n",
    "#Divido en entrenamiento y test\n",
    "#train = dataset.loc[dataset[\"foto_mes\"].isin([202102,202103])]\n",
    "train = dataset.loc[dataset[\"foto_mes\"] in [202102,202101,202007,202008,202103, 202104,202105]]\n",
    "#test = dataset.loc[dataset[\"foto_mes\"]==202105]\n",
    "#test = dataset[dataset[\"foto_mes\"]==202103]\n",
    "\n",
    "# ELIMINO VALORES NULOS\n",
    "train=train.fillna(train.mean()) # RELLENO CON LA MEDIA DE CADA COLUMNA LOS VALORES NULOS, LO NECESITA LA RED\n",
    "#test = test.fillna(test.mean())\n",
    "\n",
    "drop = [\"foto_mes\",\"numero_de_cliente\",\"clase_ternaria\"] #COLUMNAS A ELIMINAR\n",
    "\n",
    "train = train[train.columns.drop( drop)] \n",
    "#test = test[test.columns.drop(drop)]\n",
    "\n",
    "#ESCALO VARIABLES POR MÍNIMO Y MÁXIMO\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(train) # OBTENGO VARIABLES DE ESCALADO EN TRAIN\n",
    "\n",
    "train = scaler.transform(train) # LAS APLICO EN TRAIN\n",
    "#test = scaler.transform(test)  # LAS APLICO EN TEST\n",
    "variables = train.shape[1]  # OBTENGO VARIABLES TOTALES \n",
    "\n",
    "train = tf.cast(train, tf.float32)\n",
    "#test = tf.cast(test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "  def __init__(self,variables):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(variables,activation=\"relu\"),\n",
    "      layers.Dense(int(variables/2), activation=\"relu\"),\n",
    "      layers.Dense(int(variables/4), activation=\"relu\"),\n",
    "      layers.Dense(100, activation=\"relu\")])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(int(variables/4), activation=\"relu\"),\n",
    "      layers.Dense(int(variables/3), activation=\"relu\"),\n",
    "      layers.Dense(int(variables/2),activation=\"relu\"),\n",
    "      layers.Dense(variables, activation=\"sigmoid\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "  def reductor(self,x):\n",
    "      encoded = self.encoder(x)\n",
    "      return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 2s 3ms/step - loss: 0.0204 - val_loss: 0.0066\n"
     ]
    }
   ],
   "source": [
    "autoencoder=Autoencoder(variables)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "history = autoencoder.fit(x=train, y=train, \n",
    "            epochs=300, \n",
    "            batch_size=1048,\n",
    "            shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset[dataset.columns.drop(drop)]\n",
    "data = data.fillna(data.mean())\n",
    "data = scaler.transform(data)\n",
    "features_nuevas = autoencoder.reductor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(features_nuevas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dataset,features_nuevas],axis=1)\n",
    "\n",
    "if not os.path.isdir(f'./exp/{experimento}'):\n",
    "    os.makedirs(f'./exp/{experimento}')\n",
    "\n",
    "df.to_csv(f\"./exp/{experimento}/dataset.csv.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d832290213029041eddbbc4b8a0a553d5df210b193f32fda00218f7fc512b12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
